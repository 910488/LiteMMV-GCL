{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv1D, TimeDistributed, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.python.profiler import model_analyzer, option_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model):\n",
    "    input_signature = [\n",
    "    tf.TensorSpec(\n",
    "        shape=(1, *params.shape[1:]), \n",
    "        dtype=params.dtype, \n",
    "        name=params.name\n",
    "    ) for params in model.inputs\n",
    "]\n",
    "    forward_graph = tf.function(model, input_signature).get_concrete_function().graph\n",
    "    options = option_builder.ProfileOptionBuilder.float_operation()\n",
    "    graph_info = model_analyzer.profile(forward_graph, options=options)\n",
    "    # The //2 is necessary since `profile` counts multiply and accumulate\n",
    "    # as two flops, here we report the total number of multiply accumulate ops\n",
    "    flops = graph_info.total_float_ops\n",
    "    return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/pytorch/vision/blob/v0.4.0/torchvision/models/resnet.py\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.layers import TimeDistributed, LSTM, Dense\n",
    "\n",
    "kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
    "\n",
    "def conv3x3(x, out_planes, stride=1, name=None):\n",
    "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
    "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
    "\n",
    "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
    "    identity = x\n",
    "\n",
    "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
    "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
    "\n",
    "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
    "\n",
    "    if downsample is not None:\n",
    "        for layer in downsample:\n",
    "            identity = layer(identity)\n",
    "\n",
    "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
    "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_layer(x, planes, blocks, stride=1, name=None):\n",
    "    downsample = None\n",
    "    inplanes = x.shape[3]\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = [\n",
    "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
    "        ]\n",
    "\n",
    "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(x, blocks_per_layer, num_classes=1000):\n",
    "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
    "\n",
    "    x = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
    "    x = make_layer(x, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
    "    x = make_layer(x, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
    "    x = make_layer(x, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n",
    "    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(x, **kwargs):\n",
    "    # First convolution: 3Ã—3, 64 filters, stride=1.\n",
    "    x = conv3x3(x, 64, stride=1, name='conv1')\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "\n",
    "    # Residual blocks:\n",
    "    x = make_layer(x, 64, 2, name='layer1')\n",
    "    x = make_layer(x, 128, 2, stride=2, name='layer2')\n",
    "    x = make_layer(x, 256, 2, stride=2, name='layer3')\n",
    "    x = make_layer(x, 512, 2, stride=2, name='layer4')\n",
    "\n",
    "    # Global average pooling: converts feature map to a vector (should be 512-dim).\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    \n",
    "    x = layers.Dropout(0.5, name='dropout')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def resnet34(x, **kwargs):\n",
    "    return resnet(x, [3, 4, 6, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.keras.Input(shape=(32, 32, 2))\n",
    "output_tensor = resnet18(input_tensor)\n",
    "base_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "sequence_input = tf.keras.Input(shape=(20, 32, 32, 2))\n",
    "\n",
    "x = TimeDistributed(base_model)(sequence_input)\n",
    "\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "\n",
    "x = Dense(8, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 18\n",
    "ResNet18_flops = get_flops(model)\n",
    "print('FLOPs: ', ResNet18_flops)\n",
    "print('GFLOPs:', ResNet18_flops / 1e9)\n",
    "total_params = model.count_params()\n",
    "print(f\"Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "x_train_gesture  = np.load('traindata_bath_concate/data_bath_train.npy')\n",
    "gesture_labels_train = np.load('traindata_bath_concate/label_bath_train.npy')\n",
    "x_test_gesture = np.load('traindata_bath_concate/data_bath_test.npy')\n",
    "gesture_labels_test = np.load('traindata_bath_concate/label_bath_test.npy')\n",
    "x_val_gesture = np.load('traindata_bath_concate/data_bath_val.npy')\n",
    "gesture_labels_val = np.load('traindata_bath_concate/label_bath_val.npy')\n",
    "\n",
    "x_train_gesture = x_train_gesture.reshape(-1, 20, 32, 32, 2)\n",
    "x_test_gesture = x_test_gesture.reshape(-1, 20, 32, 32, 2)\n",
    "x_val_gesture = x_val_gesture.reshape(-1, 20, 32, 32, 2)\n",
    "\n",
    "print(\"Gesture data train shape:\", np.shape(x_train_gesture))\n",
    "print(\"Gesture labels train shape:\", np.shape(gesture_labels_train))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "gesture_labels_train_encoded = label_encoder.fit_transform(gesture_labels_train)\n",
    "gesture_labels_test_encoded = label_encoder.transform(gesture_labels_test)\n",
    "gesture_labels_val_encoded = label_encoder.transform(gesture_labels_val)\n",
    "\n",
    "gesture_labels_train_one_hot = to_categorical(gesture_labels_train_encoded).reshape(-1, 20, 8)\n",
    "gesture_labels_test_one_hot = to_categorical(gesture_labels_test_encoded).reshape(-1, 20, 8)\n",
    "gesture_labels_val_one_hot = to_categorical(gesture_labels_val_encoded).reshape(-1, 20, 8)\n",
    "\n",
    "gesture_labels_train_one_hot = gesture_labels_train_one_hot[:, -1, :]\n",
    "gesture_labels_test_one_hot = gesture_labels_test_one_hot[:, -1, :]\n",
    "gesture_labels_val_one_hot = gesture_labels_val_one_hot[:, -1, :]\n",
    "\n",
    "print(\"Reshaped Gesture data train shape:\", x_train_gesture.shape)\n",
    "print(\"Reshaped Gesture labels train shape:\", gesture_labels_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGIprogressBar(count, total,start):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    duration=time.time()-start\n",
    "    print('\\r[%s] %s%s ...%s sec' % (bar, percents, '%', duration),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(x_train_gesture))\n",
    "x_train_gesture = np.array(x_train_gesture)\n",
    "gesture_labels_train_one_hot = np.array(gesture_labels_train_one_hot)\n",
    "\n",
    "x_train_gesture = x_train_gesture[indices]\n",
    "gesture_labels_train_one_hot = gesture_labels_train_one_hot[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_data(model, x_data, y_data, batch_size, num_segments=10):\n",
    "    segment_size = len(x_data) // num_segments\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size if i < num_segments - 1 else len(x_data)\n",
    "\n",
    "        x_segment = x_data[start_idx:end_idx]\n",
    "        y_segment = y_data[start_idx:end_idx]\n",
    "\n",
    "        result = model.evaluate(x_segment, y_segment, batch_size=batch_size, verbose=0)\n",
    "        segment_loss = result[0]\n",
    "        predictions = model.predict(x_segment, batch_size=batch_size, verbose=0)\n",
    "\n",
    "        total_loss += segment_loss * len(y_segment)\n",
    "\n",
    "        correct_predictions += np.sum(np.argmax(predictions, axis=1) == np.argmax(y_segment, axis=1))\n",
    "        total_samples += len(y_segment)\n",
    "\n",
    "    train_loss = total_loss / total_samples\n",
    "    train_acc = correct_predictions / total_samples\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = 16\n",
    "epochs = 100\n",
    "segment_count = 5\n",
    "rec = []\n",
    "st = time.time()\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    print(f'EP: {ep + 1}')\n",
    "    segment_size = len(x_train_gesture) // segment_count\n",
    "\n",
    "    for seg in range(segment_count):\n",
    "        start_idx = seg * segment_size\n",
    "        end_idx = start_idx + segment_size\n",
    "\n",
    "        x_segment = x_train_gesture[start_idx:end_idx]\n",
    "        y_segment = gesture_labels_train_one_hot[start_idx:end_idx]\n",
    "\n",
    "        indices = np.arange(len(x_segment))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # Apply the shuffled indices to the segments\n",
    "        x_segment = x_segment[indices]\n",
    "        y_segment = y_segment[indices]\n",
    "\n",
    "        for i in range(len(x_segment) // Batch):\n",
    "            AGIprogressBar(i, len(x_segment) // Batch, st)\n",
    "            x_batch = x_segment[i * Batch:(i + 1) * Batch]\n",
    "            y_batch = y_segment[i * Batch:(i + 1) * Batch]\n",
    "\n",
    "            model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "    train_loss, train_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=x_train_gesture,\n",
    "        y_data=gesture_labels_train_one_hot,\n",
    "        batch_size=3200,\n",
    "        num_segments=20\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(' ')\n",
    "    print(f'Epoch {ep + 1} Training Loss = {train_loss}')\n",
    "    print(f'Epoch {ep + 1} Training ACC = {train_acc}')\n",
    "\n",
    "    val_loss, val_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=np.array(x_val_gesture),\n",
    "        y_data=np.array(gesture_labels_val_one_hot),\n",
    "        batch_size=3200,\n",
    "        num_segments=20\n",
    "    )\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {ep + 1} Validation Loss = {val_loss}')\n",
    "    print(f'Epoch {ep + 1} Validation ACC = {val_acc}')\n",
    "\n",
    "    os.makedirs('saved_model_Resnet', exist_ok=True)\n",
    "    if (ep + 1) % 1 == 0:\n",
    "        model.save(f'saved_model_Resnet/epoch_{ep + 1}.h5')\n",
    "        print(f'Model saved at epoch {ep + 1}')\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    model = load_model(f'saved_model_Resnet/epoch_{ep + 1}.h5')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_accuracy = val_accuracies.index(max(val_accuracies))\n",
    "best_val_accuracy = val_accuracies[best_epoch_accuracy]\n",
    "print(f\"The best epoch based on validation accuracy is: {best_epoch_accuracy + 1}, with accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('saved_model_Resnet/epoch_19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Softmax\n",
    "lstm_output = model.get_layer('lstm').output\n",
    "\n",
    "new_dense = Dense(8, name='dense', activation=None)(lstm_output)\n",
    "\n",
    "new_output = Softmax(name='softmax')(new_dense)\n",
    "\n",
    "new_model = Model(inputs=model.input, outputs=new_output)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set matplotlib parameters\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_test = np.array(gesture_labels_test_one_hot)\n",
    "\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "y_pred_prob = model.predict(x_test_gesture)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "cm = (confusion_matrix(y_true, y_pred, normalize='true'))*100\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"Accuracy: {accuracy:.10f}\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Gesture class labels\n",
    "classes = ['DoublePat', 'FallDown', 'HorizontalSwipe', 'SlowUp', 'SwipeDown', 'SwipeLeft', 'SwipeRight', 'SwipeUp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f', ax=ax, colorbar=False)\n",
    "for text in disp.text_.ravel():\n",
    "    if text.get_text():\n",
    "        text.set_text(f\"{float(text.get_text()):.2f}%\")\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.title(r\"ResNet-18 and LSTM for Hand Gesture Classification on D$_1$ (Bathroom Environment)\")\n",
    "plt.savefig('ResNet-18 and LSTM for Hand Gesture Classification on Bathroom Dataset.png', dpi=300, bbox_inches='tight')\n",
    "#plt.subplots_adjust(left=0.2, right=0.3, top=0.9, bottom=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuron analysis\n",
    "# hook Layers\n",
    "hook=[]\n",
    "id=[0, 1, 2, 3, 4]\n",
    "for i in range(len(id)):\n",
    "  hook.append(new_model.layers[id[i]].output)\n",
    "ModelExtract = Model(inputs=new_model.input, outputs=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelExtract.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(x_test_gesture))\n",
    "x_test_gesture = np.array(x_test_gesture)\n",
    "gesture_labels_test_one_hot = np.array(gesture_labels_test_one_hot)\n",
    "\n",
    "x_test_gesture = x_test_gesture[indices]\n",
    "gesture_labels_test_one_hot = gesture_labels_test_one_hot[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ModelExtract.predict(x_test_gesture)\n",
    "labels = np.argmax(gesture_labels_test_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "classes = ['DoublePat', 'FallDown', 'HorizontalSwipe', 'SlowUp', 'SwipeDown', 'SwipeLeft', 'SwipeRight', 'SwipeUp']\n",
    "\n",
    "label_to_color = {\n",
    "    'DoublePat': [1, 0, 0, 1],           # Red\n",
    "    'SwipeDown': [0, 0.5, 0, 1],         # Green\n",
    "    'SwipeUp': [0, 0, 1, 1],             # Blue\n",
    "    'SlowUp': [1, 0.65, 0, 1],           # Orange\n",
    "    'HorizontalSwipe': [1, 1, 0, 1],     # Yellow\n",
    "    'SwipeLeft': [0, 0, 0, 1],           # Black\n",
    "    'FallDown': [0.93, 0.51, 0.93, 1],   # Violet\n",
    "    'SwipeRight': [0.5, 0, 0.5, 1],      # Purple\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for label, color in label_to_color.items():\n",
    "    ax.scatter([], [], label=label, facecolors='none', edgecolors=color, marker='o', s=50)\n",
    "\n",
    "ax.legend(loc='center', frameon=False, ncol=4)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig('legend_only_3x4.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from matplotlib import pyplot as plt\n",
    "PCA=[]\n",
    "\n",
    "classes = ['DoublePat', 'FallDown', 'HorizontalSwipe', 'SlowUp', 'SwipeDown', 'SwipeLeft', 'SwipeRight', 'SwipeUp']\n",
    "\n",
    "label_to_color = {\n",
    "    'DoublePat': [1, 0, 0, 1],           # Red\n",
    "    'SwipeDown': [0, 0.5, 0, 1],         # Green\n",
    "    'SwipeUp': [0, 0, 1, 1],             # Blue\n",
    "    'SlowUp': [1, 0.65, 0, 1],           # Orange\n",
    "    'HorizontalSwipe': [1, 1, 0, 1],     # Yellow\n",
    "    'SwipeLeft': [0, 0, 0, 1],           # Black\n",
    "    'FallDown': [0.93, 0.51, 0.93, 1],   # Violet\n",
    "    'SwipeRight': [0.5, 0, 0.5, 1],      # Purple\n",
    "}\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    input=np.reshape(predictions[i],[len(predictions[i]),-1])\n",
    "    pca=decomposition.PCA(n_components=2)\n",
    "    pca.fit(input)\n",
    "    PCA.append(pca)\n",
    "    Dim2=PCA[-1].transform(input)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if new_model.layers[id[i]].name == 'input_2':\n",
    "        title = \"Gesture Class Distribution in Our D$_1$ Dataset via PCA using ResNet-18 + LSTM (Input Layer)\"\n",
    "    elif new_model.layers[id[i]].name == 'dense':\n",
    "        title = r\"ResNet-18 + LSTM: D$_1$ (Bathroom Environment), \" + model.layers[id[i]].name + ': '+f'{predictions[i].shape}'\n",
    "    else:\n",
    "        title = new_model.layers[id[i]].name+': '+f'{predictions[i].shape}'\n",
    "    plt.title(title)\n",
    "    for cl in range(8):\n",
    "        chos=Dim2[np.argwhere(labels==cl).reshape([-1])]\n",
    "        color = label_to_color[classes[cl]]\n",
    "        plt.scatter(chos[:, 0], \n",
    "                   chos[:, 1], \n",
    "                   label=classes[cl],\n",
    "                   facecolors='none', \n",
    "                   edgecolors=color,\n",
    "                   marker='o', \n",
    "                   s=10)\n",
    "    plt.legend(loc=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KKT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
