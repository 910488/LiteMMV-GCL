{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv1D, TimeDistributed, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function\n",
    "def l2_loss(y_true, y_pred):\n",
    "    diff = y_true - y_pred\n",
    "    loss = tf.reduce_mean(tf.square(diff))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'saved_model_cnn_stage0/epoch_732.h5', custom_objects={'l2_loss': l2_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "x_train_gesture  = np.load('traindata_bath_concate/data_bath_train.npy')\n",
    "gesture_labels_train = np.load('traindata_bath_concate/label_bath_train.npy')\n",
    "x_test_gesture = np.load('traindata_bath_concate/data_bath_test.npy')\n",
    "gesture_labels_test = np.load('traindata_bath_concate/label_bath_test.npy')\n",
    "x_val_gesture = np.load('traindata_bath_concate/data_bath_val.npy')\n",
    "gesture_labels_val = np.load('traindata_bath_concate/label_bath_val.npy')\n",
    "\n",
    "print(\"Gesture data train shape:\", np.shape(x_train_gesture))\n",
    "print(\"Gesture labels train shape:\", np.shape(gesture_labels_train))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "gesture_labels_train_encoded = label_encoder.fit_transform(gesture_labels_train)\n",
    "gesture_labels_test_encoded = label_encoder.transform(gesture_labels_test)\n",
    "gesture_labels_val_encoded = label_encoder.transform(gesture_labels_val)\n",
    "\n",
    "gesture_labels_train_one_hot = to_categorical(gesture_labels_train_encoded)\n",
    "gesture_labels_test_one_hot = to_categorical(gesture_labels_test_encoded)\n",
    "gesture_labels_val_one_hot = to_categorical(gesture_labels_val_encoded)\n",
    "\n",
    "gesture_labels_train_one_hot = np.reshape(gesture_labels_train_one_hot, (-1, 1, 8))\n",
    "gesture_labels_test_one_hot = np.reshape(gesture_labels_test_one_hot, (-1, 1, 8))\n",
    "gesture_labels_val_one_hot = np.reshape(gesture_labels_val_one_hot, (-1, 1, 8))\n",
    "\n",
    "print(\"Reshaped Gesture data train shape:\", x_train_gesture.shape)\n",
    "print(\"Reshaped Gesture labels train shape:\", gesture_labels_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGIprogressBar(count, total,start):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    duration=time.time()-start\n",
    "    print('\\r[%s] %s%s ...%s sec' % (bar, percents, '%', duration),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(x_train_gesture))\n",
    "x_train_gesture = np.array(x_train_gesture)\n",
    "gesture_labels_train_one_hot = np.array(gesture_labels_train_one_hot)\n",
    "\n",
    "x_train_gesture = x_train_gesture[indices]\n",
    "gesture_labels_train_one_hot = gesture_labels_train_one_hot[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=l2_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = 8960\n",
    "epochs = 100\n",
    "segment_count = 5\n",
    "rec = []\n",
    "st = time.time()\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    print(f'EP: {ep + 1}')\n",
    "    segment_size = len(x_train_gesture) // segment_count\n",
    "\n",
    "    for seg in range(segment_count):\n",
    "        start_idx = seg * segment_size\n",
    "        end_idx = start_idx + segment_size\n",
    "\n",
    "        x_segment = x_train_gesture[start_idx:end_idx]\n",
    "        y_segment = gesture_labels_train_one_hot[start_idx:end_idx]\n",
    "\n",
    "        indices = np.arange(len(x_segment))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        x_segment = x_segment[indices]\n",
    "        y_segment = y_segment[indices]\n",
    "\n",
    "        for i in range(len(x_segment) // Batch):\n",
    "            AGIprogressBar(i, len(x_segment) // Batch, st)\n",
    "            x_batch = x_segment[i * Batch:(i + 1) * Batch]\n",
    "            y_batch = y_segment[i * Batch:(i + 1) * Batch]\n",
    "\n",
    "            model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "    train_result = model.evaluate(x_train_gesture, gesture_labels_train_one_hot, batch_size=2400, verbose=0)\n",
    "    train_loss = train_result[0]\n",
    "    train_acc = train_result[1]\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(' ')\n",
    "    print(f'Epoch {ep + 1} Training Loss = {train_loss}')\n",
    "    print(f'Epoch {ep + 1} Training ACC = {train_acc}')\n",
    "\n",
    "    val_result = model.evaluate(x_val_gesture, gesture_labels_val_one_hot, batch_size=2400, verbose=0)\n",
    "    val_loss = val_result[0]\n",
    "    val_acc = val_result[1]\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {ep + 1} Validation Loss = {val_loss}')\n",
    "    print(f'Epoch {ep + 1} Validation ACC = {val_acc}')\n",
    "\n",
    "    os.makedirs('saved_model_cnn_stage1', exist_ok=True)\n",
    "    if (ep + 1) % 1 == 0:\n",
    "        model.save(f'saved_model_cnn_stage1/epoch_{ep + 1}.h5')\n",
    "        print(f'Model saved at epoch {ep + 1}')\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    model = load_model(f'saved_model_cnn_stage1/epoch_{ep + 1}.h5', custom_objects={'l2_loss': l2_loss})\n",
    "\n",
    "\n",
    "best_epoch_accuracy = val_accuracies.index(max(val_accuracies))\n",
    "best_val_accuracy = val_accuracies[best_epoch_accuracy]\n",
    "print(f\"The best epoch based on validation accuracy is: {best_epoch_accuracy + 1}, with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('saved_model_cnn_stage1/epoch_100.h5', custom_objects={'l2_loss': l2_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook BN Layer\n",
    "hook=[]\n",
    "id=[10]\n",
    "for i in range(len(id)):\n",
    "  hook.append(model.layers[id[i]].output)\n",
    "ModelExtract = Model(inputs=model.input, outputs=hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelExtract.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction results\n",
    "os.mkdir('Train_Dataset_For_LSTM')\n",
    "predictions = ModelExtract.predict(x_train_gesture)\n",
    "labels = np.squeeze(gesture_labels_train_one_hot, axis=1)\n",
    "np.save('Train_Dataset_For_LSTM/predictions_train.npy', predictions)\n",
    "np.save('Train_Dataset_For_LSTM/predictions_labels_train', labels)\n",
    "\n",
    "predictions = ModelExtract.predict(x_val_gesture)\n",
    "labels = np.squeeze(gesture_labels_val_one_hot, axis=1)\n",
    "np.save('Train_Dataset_For_LSTM/predictions_val.npy', predictions)\n",
    "np.save('Train_Dataset_For_LSTM/predictions_labels_val', labels)\n",
    "\n",
    "predictions = ModelExtract.predict(x_test_gesture)\n",
    "labels = np.squeeze(gesture_labels_test_one_hot, axis=1)\n",
    "np.save('Train_Dataset_For_LSTM/predictions_test.npy', predictions)\n",
    "np.save('Train_Dataset_For_LSTM/predictions_labels_test', labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KKT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
