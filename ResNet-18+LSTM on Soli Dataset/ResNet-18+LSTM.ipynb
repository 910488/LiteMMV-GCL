{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv1D, TimeDistributed, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.python.profiler import model_analyzer, option_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model):\n",
    "    input_signature = [\n",
    "    tf.TensorSpec(\n",
    "        shape=(1, *params.shape[1:]), \n",
    "        dtype=params.dtype, \n",
    "        name=params.name\n",
    "    ) for params in model.inputs\n",
    "]\n",
    "    forward_graph = tf.function(model, input_signature).get_concrete_function().graph\n",
    "    options = option_builder.ProfileOptionBuilder.float_operation()\n",
    "    graph_info = model_analyzer.profile(forward_graph, options=options)\n",
    "    # The //2 is necessary since `profile` counts multiply and accumulate\n",
    "    # as two flops, here we report the total number of multiply accumulate ops\n",
    "    flops = graph_info.total_float_ops\n",
    "    return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/pytorch/vision/blob/v0.4.0/torchvision/models/resnet.py\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.layers import TimeDistributed, LSTM, Dense\n",
    "\n",
    "kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
    "\n",
    "def conv3x3(x, out_planes, stride=1, name=None):\n",
    "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
    "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
    "\n",
    "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
    "    identity = x\n",
    "\n",
    "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
    "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
    "\n",
    "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
    "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
    "\n",
    "    if downsample is not None:\n",
    "        for layer in downsample:\n",
    "            identity = layer(identity)\n",
    "\n",
    "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
    "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def make_layer(x, planes, blocks, stride=1, name=None):\n",
    "    downsample = None\n",
    "    inplanes = x.shape[3]\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = [\n",
    "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
    "        ]\n",
    "\n",
    "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
    "    for i in range(1, blocks):\n",
    "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(x, blocks_per_layer, num_classes=1000):\n",
    "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
    "\n",
    "    x = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
    "    x = make_layer(x, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
    "    x = make_layer(x, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
    "    x = make_layer(x, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n",
    "    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(x, **kwargs):\n",
    "    # First convolution: 3Ã—3, 64 filters, stride=1.\n",
    "    x = conv3x3(x, 64, stride=1, name='conv1')\n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
    "    x = layers.ReLU(name='relu1')(x)\n",
    "\n",
    "    # Residual blocks:\n",
    "    x = make_layer(x, 64, 2, name='layer1')\n",
    "    x = make_layer(x, 128, 2, stride=2, name='layer2')\n",
    "    x = make_layer(x, 256, 2, stride=2, name='layer3')\n",
    "    x = make_layer(x, 512, 2, stride=2, name='layer4')\n",
    "\n",
    "    # Global average pooling: converts feature map to a vector (should be 512-dim).\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    \n",
    "    x = layers.Dropout(0.5, name='dropout')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def resnet34(x, **kwargs):\n",
    "    return resnet(x, [3, 4, 6, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.keras.Input(shape=(32, 32, 4))\n",
    "output_tensor = resnet18(input_tensor)\n",
    "base_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "sequence_input = tf.keras.Input(shape=(20, 32, 32, 4))\n",
    "\n",
    "x = TimeDistributed(base_model)(sequence_input)\n",
    "\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "\n",
    "x = Dense(11, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.keras.Input(shape=(32, 32, 4))\n",
    "output_tensor = resnet18(input_tensor)\n",
    "base_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "sequence_input = tf.keras.Input(shape=(35, 32, 32, 4))\n",
    "\n",
    "x = TimeDistributed(base_model)(sequence_input)\n",
    "\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "\n",
    "x = Dense(11, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 18\n",
    "ResNet18_flops = get_flops(model)\n",
    "print('FLOPs: ', ResNet18_flops)\n",
    "print('GFLOPs:', ResNet18_flops / 1e9)\n",
    "total_params = model.count_params()\n",
    "print(f\"Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Gesture Data (From path)\n",
    "def load_gesture_path(directory):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    for category in os.listdir(directory):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        if len(os.listdir(category_path))!=1:\n",
    "            if os.path.isdir(category_path):\n",
    "                print(f\"Loading category: {category}\")\n",
    "                for filename in os.listdir(category_path):\n",
    "                    if filename.endswith('.npy'):\n",
    "                        file_paths.append((category, os.path.join(category_path, filename)))\n",
    "                        labels.append(category)  \n",
    "    return file_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def copy_files(file_paths, base_dir):\n",
    "    for category, file_path in file_paths:\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        if not os.path.exists(category_dir):\n",
    "            os.makedirs(category_dir)\n",
    "        shutil.copy(file_path, category_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "gesture_data_path, gesture_label = load_gesture_path('dataset-image')\n",
    "print(gesture_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('traindata')\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    gesture_data_path, gesture_label, test_size=0.4, random_state=42, stratify=gesture_label\n",
    ")\n",
    "\n",
    "copy_files(train_paths, 'traindata\\\\train')\n",
    "copy_files(test_paths, 'traindata\\\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traindata_concate(directory):\n",
    "    gesture_data = []\n",
    "    labels = []\n",
    "    TimeSp = 20\n",
    "    for category in os.listdir(directory):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            print(f\"Loading category: {category}\")\n",
    "            for filename in os.listdir(category_path):\n",
    "                file_path = os.path.join(category_path, filename)\n",
    "                if filename.endswith('.npy'):\n",
    "                    data = np.load(file_path)\n",
    "                    \n",
    "                if data.shape == (20, 32, 32, 4):\n",
    "                    gesture_data.append(data)\n",
    "                    labels.append(category)\n",
    "                    \n",
    "                elif data.shape[0] < TimeSp:\n",
    "                    print(f\"Skipping {file_path}, not enough data for TimeSp\")\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    for i in range(100000):\n",
    "                        if i + TimeSp >= data.shape[0]:\n",
    "                            break\n",
    "                        gesture_data.append(data[i:i+TimeSp, :, :, :])\n",
    "                        labels.append(category)\n",
    "    return np.array(gesture_data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = traindata_concate('traindata\\\\train')\n",
    "#y_train = np.repeat(y_train, 20)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "x_test, y_test = traindata_concate('traindata\\\\test')\n",
    "#y_test = np.repeat(y_test, 20)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "os.mkdir('traindata_concate')\n",
    "np.save('traindata_concate/data_train.npy', x_train)\n",
    "np.save('traindata_concate/data_test.npy', x_test)\n",
    "\n",
    "np.save('traindata_concate/label_train.npy', y_train)\n",
    "np.save('traindata_concate/label_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "x_train_gesture  = np.load('traindata_concate\\data_train.npy')\n",
    "gesture_labels_train = np.load('traindata_concate\\label_train.npy')\n",
    "x_test_gesture = np.load('traindata_concate\\data_test.npy')\n",
    "gesture_labels_test = np.load('traindata_concate\\label_test.npy')\n",
    "\n",
    "print(\"Gesture data train shape:\", np.shape(x_train_gesture))\n",
    "print(\"Gesture labels train shape:\", np.shape(gesture_labels_train))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "gesture_labels_train_encoded = label_encoder.fit_transform(gesture_labels_train)\n",
    "gesture_labels_test_encoded = label_encoder.transform(gesture_labels_test)\n",
    "\n",
    "gesture_labels_train_one_hot = to_categorical(gesture_labels_train_encoded)\n",
    "gesture_labels_test_one_hot = to_categorical(gesture_labels_test_encoded)\n",
    "\n",
    "print(\"Reshaped Gesture data train shape:\", x_train_gesture.shape)\n",
    "print(\"Reshaped Gesture labels train shape:\", gesture_labels_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGIprogressBar(count, total,start):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    duration=time.time()-start\n",
    "    print('\\r[%s] %s%s ...%s sec' % (bar, percents, '%', duration),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(x_train_gesture))\n",
    "x_train_gesture = np.array(x_train_gesture)\n",
    "gesture_labels_train_one_hot = np.array(gesture_labels_train_one_hot)\n",
    "\n",
    "x_train_gesture = x_train_gesture[indices]\n",
    "gesture_labels_train_one_hot = gesture_labels_train_one_hot[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_data(model, x_data, y_data, batch_size, num_segments=10):\n",
    "    segment_size = len(x_data) // num_segments\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size if i < num_segments - 1 else len(x_data)\n",
    "\n",
    "        x_segment = x_data[start_idx:end_idx]\n",
    "        y_segment = y_data[start_idx:end_idx]\n",
    "\n",
    "        result = model.evaluate(x_segment, y_segment, batch_size=batch_size, verbose=0)\n",
    "        segment_loss = result[0]\n",
    "        predictions = model.predict(x_segment, batch_size=batch_size, verbose=0)\n",
    "\n",
    "        total_loss += segment_loss * len(y_segment)\n",
    "\n",
    "        correct_predictions += np.sum(np.argmax(predictions, axis=1) == np.argmax(y_segment, axis=1))\n",
    "        total_samples += len(y_segment)\n",
    "\n",
    "    train_loss = total_loss / total_samples\n",
    "    train_acc = correct_predictions / total_samples\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = 16\n",
    "epochs = 100\n",
    "segment_count = 25\n",
    "rec = []\n",
    "st = time.time()\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    print(f'EP: {ep + 1}')\n",
    "    segment_size = len(x_train_gesture) // segment_count\n",
    "\n",
    "    for seg in range(segment_count):\n",
    "        start_idx = seg * segment_size\n",
    "        end_idx = start_idx + segment_size\n",
    "\n",
    "        x_segment = x_train_gesture[start_idx:end_idx]\n",
    "        y_segment = gesture_labels_train_one_hot[start_idx:end_idx]\n",
    "\n",
    "        indices = np.arange(len(x_segment))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # Apply the shuffled indices to the segments\n",
    "        x_segment = x_segment[indices]\n",
    "        y_segment = y_segment[indices]\n",
    "\n",
    "        for i in range(len(x_segment) // Batch):\n",
    "            AGIprogressBar(i, len(x_segment) // Batch, st)\n",
    "            x_batch = x_segment[i * Batch:(i + 1) * Batch]\n",
    "            y_batch = y_segment[i * Batch:(i + 1) * Batch]\n",
    "\n",
    "            model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "    train_loss, train_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=x_train_gesture,\n",
    "        y_data=gesture_labels_train_one_hot,\n",
    "        batch_size=3200,\n",
    "        num_segments=700\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(' ')\n",
    "    print(f'Epoch {ep + 1} Training Loss = {train_loss}')\n",
    "    print(f'Epoch {ep + 1} Training ACC = {train_acc}')\n",
    "\n",
    "    val_loss, val_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=np.array(x_test_gesture),\n",
    "        y_data=np.array(gesture_labels_test_one_hot),\n",
    "        batch_size=3200,\n",
    "        num_segments=700\n",
    "    )\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {ep + 1} Validation Loss = {val_loss}')\n",
    "    print(f'Epoch {ep + 1} Validation ACC = {val_acc}')\n",
    "\n",
    "    os.makedirs('saved_model_Resnet', exist_ok=True)\n",
    "    if (ep + 1) % 1 == 0:\n",
    "        model.save(f'saved_model_Resnet/epoch_{ep + 1}.h5')\n",
    "        print(f'Model saved at epoch {ep + 1}')\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    model = load_model(f'saved_model_Resnet/epoch_{ep + 1}.h5')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('saved_model_Resnet/epoch_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Softmax\n",
    "lstm_output = model.get_layer('lstm').output\n",
    "\n",
    "new_dense = Dense(11, name='dense', activation=None)(lstm_output)\n",
    "\n",
    "new_output = Softmax(name='softmax')(new_dense)\n",
    "\n",
    "new_model = Model(inputs=model.input, outputs=new_output)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_CM_data(model, x_data, y_data, batch_size, num_segments=10):\n",
    "    segment_size = len(x_data) // num_segments\n",
    "\n",
    "    all_preds = []  # To store all predictions\n",
    "    all_trues = []  # To store all true labels\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size if i < num_segments - 1 else len(x_data)\n",
    "\n",
    "        x_segment = x_data[start_idx:end_idx]\n",
    "        y_segment = y_data[start_idx:end_idx]\n",
    "\n",
    "        predictions = model.predict(x_segment, batch_size=batch_size, verbose=0)\n",
    "        \n",
    "        pred = np.argmax(predictions, axis=1)\n",
    "        true = np.argmax(y_segment, axis=1)\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true)\n",
    "\n",
    "    # Combine all predictions and true labels into single arrays\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_trues)\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "y_test = gesture_labels_test_one_hot\n",
    "\n",
    "y_true, y_pred = get_CM_data(model, x_test_gesture, gesture_labels_test_one_hot, 32, 100)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = (confusion_matrix(y_true, y_pred, normalize='true'))*100\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Gesture class labels\n",
    "classes = ['gesture_0', 'gesture_1', 'gesture_2', 'gesture_3', 'gesture_4', 'gesture_5', 'gesture_6', 'gesture_7', 'gesture_8', 'gesture_9', 'gesture_10']\n",
    "\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(3.5, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f', ax=ax, colorbar=False)\n",
    "for text in disp.text_.ravel():\n",
    "    if text.get_text():\n",
    "        text.set_text(f\"{float(text.get_text()):.2f}%\")\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.title(r\"ResNet-18 and LSTM for Hand Gesture Classification on Soli Dataset\")\n",
    "plt.savefig('ResNet-18 and LSTM for Hand Gesture Classification on Soli Dataset.png', dpi=300, bbox_inches='tight')\n",
    "#plt.subplots_adjust(left=0.2, right=0.3, top=0.9, bottom=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook Layers\n",
    "hook=[]\n",
    "id=[0, 1, 2, 3, 4]\n",
    "for i in range(len(id)):\n",
    "  hook.append(new_model.layers[id[i]].output)\n",
    "ModelExtract = Model(inputs=model.input, outputs=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(x_test_gesture)\n",
    "for i in range(n):\n",
    "    j = np.random.randint(i, n)\n",
    "    # Swap rows i and j for data and labels\n",
    "    x_test_gesture[[i, j]], x_test_gesture[[j, i]] = x_test_gesture[[j, i]], x_test_gesture[[i, j]]\n",
    "    gesture_labels_test_one_hot[[i, j]], gesture_labels_test_one_hot[[j, i]] = gesture_labels_test_one_hot[[j, i]], gesture_labels_test_one_hot[[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_predict_data(model, x_data, batch_size, num_segments=10):\n",
    "    segment_size = len(x_data) // num_segments\n",
    "    x_predict = []\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size if i < num_segments - 1 else len(x_data)\n",
    "\n",
    "        x_segment = x_data[start_idx:end_idx]\n",
    "\n",
    "        predictions = model.predict(x_segment, batch_size=batch_size, verbose=0)\n",
    "        x_predict.append(predictions)\n",
    "\n",
    "    return x_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predict_data(ModelExtract, x_test_gesture[:20000], 3200, 100)\n",
    "labels = np.argmax(gesture_labels_test_one_hot[:20000], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import decomposition\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "PCA = []\n",
    "classes = ['gesture_0', 'gesture_1', 'gesture_2', 'gesture_3', 'gesture_4', 'gesture_5', \n",
    "           'gesture_6', 'gesture_7', 'gesture_8', 'gesture_9', 'gesture_10']\n",
    "\n",
    "label_to_color = {\n",
    "    'gesture_0': [1, 0, 0, 1],          # Red\n",
    "    'gesture_1': [0, 0.5, 0, 1],        # Green\n",
    "    'gesture_2': [0, 0, 1, 1],          # Blue\n",
    "    'gesture_3': [1, 0.65, 0, 1],       # Orange\n",
    "    'gesture_4': [1, 1, 0, 1],          # Yellow\n",
    "    'gesture_5': [0, 0, 0, 1],          # Black\n",
    "    'gesture_6': [0.93, 0.51, 0.93, 1], # Violet\n",
    "    'gesture_7': [0.5, 0, 0.5, 1],      # Purple\n",
    "    'gesture_8': [0, 1, 1, 1],          # Cyan\n",
    "    'gesture_9': [0.5, 0.5, 0.5, 1],    # Gray\n",
    "    'gesture_10': [0.6, 0.2, 0.2, 1],   # Brown\n",
    "}\n",
    "\n",
    "for k in range(5):\n",
    "    layer_outputs = [predictions[i][k] for i in range(100)]\n",
    "    layer_outputs = np.concatenate(layer_outputs, axis=0)\n",
    "    layer_outputs_flat = layer_outputs.reshape(layer_outputs.shape[0], -1)\n",
    "    pca = decomposition.PCA(n_components=2)\n",
    "    pca.fit(layer_outputs_flat)\n",
    "    Dim2 = pca.transform(layer_outputs_flat)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    layer_name = new_model.layers[id[k]].name\n",
    "    if layer_name == 'input_2':\n",
    "        title = \"Gesture Class Distribution in Soli Dataset via PCA using ResNet-18 + LSTM\"\n",
    "    elif layer_name == 'dense':\n",
    "        title = \"Learned Feature Distribution in Soli Dataset via PCA using ResNet-18 + LSTM (Dense Layer)\"\n",
    "    else:\n",
    "        title = f'{layer_name}: (50000, {\", \".join(map(str, predictions[0][k].shape[1:]))})'\n",
    "    plt.title(title)\n",
    "    for cl in range(11):\n",
    "        chos = Dim2[np.where(labels == cl)[0]]\n",
    "        color = label_to_color[classes[cl]]\n",
    "        plt.scatter(chos[:, 0], \n",
    "                    chos[:, 1], \n",
    "                    label=classes[cl],\n",
    "                    facecolors='none',        \n",
    "                    edgecolors=color,         \n",
    "                    marker='o', \n",
    "                    s=10)\n",
    "    fig = plt.gcf()\n",
    "    with open(f'plot_layer_{k}.pkl', 'wb') as f:\n",
    "        pickle.dump(fig, f)\n",
    "    plt.savefig(title, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KKT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
