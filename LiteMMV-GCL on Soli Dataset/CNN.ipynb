{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv1D, TimeDistributed, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (from path)\n",
    "def load_gesture_path(directory):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    for category in os.listdir(directory):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        if len(os.listdir(category_path))!=1:\n",
    "            if os.path.isdir(category_path):\n",
    "                print(f\"Loading category: {category}\")\n",
    "                for filename in os.listdir(category_path):\n",
    "                    if filename.endswith('.npy'):\n",
    "                        file_paths.append((category, os.path.join(category_path, filename)))\n",
    "                        labels.append(category)  \n",
    "    return file_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def copy_files(file_paths, base_dir):\n",
    "    for category, file_path in file_paths:\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        if not os.path.exists(category_dir):\n",
    "            os.makedirs(category_dir)\n",
    "        shutil.copy(file_path, category_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "gesture_data_path, gesture_label = load_gesture_path('dataset-image')\n",
    "print(gesture_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing\n",
    "os.mkdir('traindata')\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    gesture_data_path, gesture_label, test_size=0.4, random_state=42, stratify=gesture_label\n",
    ")\n",
    "\n",
    "copy_files(train_paths, 'traindata\\\\train')\n",
    "copy_files(test_paths, 'traindata\\\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traindata_concate(directory):\n",
    "    gesture_data = []\n",
    "    labels = []\n",
    "    TimeSp = 35\n",
    "    for category in os.listdir(directory):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            print(f\"Loading category: {category}\")\n",
    "            for filename in os.listdir(category_path):\n",
    "                file_path = os.path.join(category_path, filename)\n",
    "                if filename.endswith('.npy'):\n",
    "                    data = np.load(file_path)\n",
    "                    \n",
    "                if data.shape == (35, 32, 32, 4):\n",
    "                    gesture_data.append(data)\n",
    "                    labels.append(category)\n",
    "                    \n",
    "                elif data.shape[0] < TimeSp:\n",
    "                    print(f\"Skipping {file_path}, not enough data for TimeSp\")\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    for i in range(100000):\n",
    "                        if i + TimeSp >= data.shape[0]:\n",
    "                            break\n",
    "                        gesture_data.append(data[i:i+TimeSp, :, :, :])\n",
    "                        labels.append(category)\n",
    "    return np.array(gesture_data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = traindata_concate('traindata\\\\train')\n",
    "y_train = np.repeat(y_train, 35)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "x_test, y_test = traindata_concate('traindata\\\\test')\n",
    "y_test = np.repeat(y_test, 35)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "os.mkdir('traindata_concate_35')\n",
    "np.save('traindata_concate_35/data_train.npy', x_train)\n",
    "np.save('traindata_concate_35/data_test.npy', x_test)\n",
    "\n",
    "np.save('traindata_concate_35/label_train.npy', y_train)\n",
    "np.save('traindata_concate_35/label_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function\n",
    "def l2_loss(y_true, y_pred):\n",
    "    diff = y_true - y_pred\n",
    "    loss = tf.reduce_mean(tf.square(diff))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€Define a lightweight CNN model\n",
    "main_input=tf.keras.layers.Input(shape=(32,32,4), name=\"input_1\")\n",
    "\n",
    "x=tf.keras.layers.DepthwiseConv2D(3, strides=(2, 2), use_bias=False, name=\"online_cnn_fw/depthwise_conv2d_9/depthwise1\")(main_input)\n",
    "x=tf.keras.layers.Conv2D(32, 1, activation='relu', use_bias=False, name=\"online_cnn_fw/conv2d_9/Conv2D\")(x)\n",
    "x=tf.keras.layers.DepthwiseConv2D(3, strides=(2, 2), use_bias=False, name=\"online_cnn_fw/depthwise_conv2d_10/depthwise1\")(x)\n",
    "x=tf.keras.layers.Conv2D(64, 1, activation='relu', use_bias=False, name=\"online_cnn_fw/conv2d_10/Conv2D\")(x)\n",
    "x=tf.keras.layers.Dropout(0.5, name=\"dropout\")(x) \n",
    "x=tf.keras.layers.DepthwiseConv2D(3, strides=(2, 2), use_bias=False, name=\"online_cnn_fw/depthwise_conv2d_11/depthwise1\")(x)\n",
    "x=tf.keras.layers.Conv2D(128, 1, activation='relu', use_bias=False, name=\"online_cnn_fw/conv2d_11/Conv2D1\")(x)\n",
    "x=tf.keras.layers.Dropout(0.5, name=\"dropout_1\")(x) \n",
    "x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x=tf.keras.layers.BatchNormalization(name='batch_normalization')(x)\n",
    "x=tf.keras.layers.Reshape((1,128))(x)\n",
    "\n",
    "cnnmodel=tf.keras.models.Model(inputs=main_input, outputs=x)\n",
    "\n",
    "cnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Dense classification layer with 8 output units and softmax activation\n",
    "x = cnnmodel.output\n",
    "\n",
    "predictions = Dense(11, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=cnnmodel.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "x_train_gesture  = np.load('traindata_concate_35\\data_train.npy')\n",
    "gesture_labels_train = np.load('traindata_concate_35\\label_train.npy')\n",
    "x_test_gesture = np.load('traindata_concate_35\\data_test.npy')\n",
    "gesture_labels_test = np.load('traindata_concate_35\\label_test.npy')\n",
    "\n",
    "x_train_gesture = x_train_gesture.reshape(-1, 32, 32, 4)\n",
    "x_test_gesture = x_test_gesture.reshape(-1, 32, 32, 4)\n",
    "\n",
    "gesture_labels_train = np.repeat(gesture_labels_train, 35)\n",
    "gesture_labels_test = np.repeat(gesture_labels_test, 35)\n",
    "\n",
    "print(\"Gesture data train shape:\", np.shape(x_train_gesture))\n",
    "print(\"Gesture labels train shape:\", np.shape(gesture_labels_train))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "gesture_labels_train_encoded = label_encoder.fit_transform(gesture_labels_train)\n",
    "gesture_labels_test_encoded = label_encoder.transform(gesture_labels_test)\n",
    "\n",
    "gesture_labels_train_one_hot = to_categorical(gesture_labels_train_encoded).reshape(-1, 1, 11)\n",
    "gesture_labels_test_one_hot = to_categorical(gesture_labels_test_encoded).reshape(-1, 1, 11)\n",
    "\n",
    "print(\"Reshaped Gesture data train shape:\", x_train_gesture.shape)\n",
    "print(\"Reshaped Gesture labels train shape:\", gesture_labels_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=l2_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGIprogressBar(count, total,start):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    duration=time.time()-start\n",
    "    print('\\r[%s] %s%s ...%s sec' % (bar, percents, '%', duration),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(x_train_gesture)\n",
    "for i in range(n):\n",
    "    j = np.random.randint(i, n)\n",
    "    # Swap rows i and j for data and labels\n",
    "    x_train_gesture[[i, j]], x_train_gesture[[j, i]] = x_train_gesture[[j, i]], x_train_gesture[[i, j]]\n",
    "    gesture_labels_train_one_hot[[i, j]], gesture_labels_train_one_hot[[j, i]] = gesture_labels_train_one_hot[[j, i]], gesture_labels_train_one_hot[[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_data(model, x_data, y_data, batch_size, num_segments=10):\n",
    "    segment_size = len(x_data) // num_segments\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size if i < num_segments - 1 else len(x_data)\n",
    "\n",
    "        x_segment = x_data[start_idx:end_idx]\n",
    "        y_segment = y_data[start_idx:end_idx]\n",
    "\n",
    "        result = model.evaluate(x_segment, y_segment, batch_size=batch_size, verbose=0)\n",
    "        segment_loss = result[0]\n",
    "        predictions = model.predict(x_segment, batch_size=batch_size, verbose=0)\n",
    "\n",
    "        total_loss += segment_loss * len(y_segment)\n",
    "\n",
    "        correct_predictions += np.sum(np.argmax(predictions, axis=2) == np.argmax(y_segment, axis=2))\n",
    "        total_samples += len(y_segment)\n",
    "\n",
    "    train_loss = total_loss / total_samples\n",
    "    train_acc = correct_predictions / total_samples\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = 8960\n",
    "epochs = 1000\n",
    "segment_count = 25\n",
    "rec = []\n",
    "st = time.time()\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    print(f'EP: {ep + 1}')\n",
    "    segment_size = len(x_train_gesture) // segment_count\n",
    "\n",
    "    for seg in range(segment_count):\n",
    "        start_idx = seg * segment_size\n",
    "        end_idx = start_idx + segment_size\n",
    "\n",
    "        x_segment = x_train_gesture[start_idx:end_idx]\n",
    "        y_segment = gesture_labels_train_one_hot[start_idx:end_idx]\n",
    "\n",
    "        indices = np.arange(len(x_segment))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # Apply the shuffled indices to the segments\n",
    "        x_segment = x_segment[indices]\n",
    "        y_segment = y_segment[indices]\n",
    "\n",
    "        for i in range(len(x_segment) // Batch):\n",
    "            AGIprogressBar(i, len(x_segment) // Batch, st)\n",
    "            x_batch = x_segment[i * Batch:(i + 1) * Batch]\n",
    "            y_batch = y_segment[i * Batch:(i + 1) * Batch]\n",
    "\n",
    "            model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "    train_loss, train_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=x_train_gesture,\n",
    "        y_data=gesture_labels_train_one_hot,\n",
    "        batch_size=3200,\n",
    "        num_segments=700\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(' ')\n",
    "    print(f'Epoch {ep + 1} Training Loss = {train_loss}')\n",
    "    print(f'Epoch {ep + 1} Training ACC = {train_acc}')\n",
    "\n",
    "    val_loss, val_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=x_test_gesture,\n",
    "        y_data=gesture_labels_test_one_hot,\n",
    "        batch_size=3200,\n",
    "        num_segments=700\n",
    "    )\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "\n",
    "    print(f'Epoch {ep + 1} Validation Loss = {val_loss}')\n",
    "    print(f'Epoch {ep + 1} Validation ACC = {val_acc}')\n",
    "\n",
    "    os.makedirs('saved_model_our_cnn', exist_ok=True)\n",
    "    if (ep + 1) % 1 == 0:\n",
    "        model.save(f'saved_model_our_cnn/epoch_{ep + 1}.h5')\n",
    "        print(f'Model saved at epoch {ep + 1}')\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    model = load_model(f'saved_model_our_cnn/epoch_{ep + 1}.h5', custom_objects={'l2_loss': l2_loss})\n",
    "\n",
    "\n",
    "best_epoch_accuracy = val_accuracies.index(max(val_accuracies))\n",
    "best_val_accuracy = val_accuracies[best_epoch_accuracy]\n",
    "print(f\"The best epoch based on validation accuracy is: {best_epoch_accuracy + 1}, with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_data = {}\n",
    "\n",
    "with open('log.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        match = re.search(r'Epoch (\\d+) Training Loss = (\\d+\\.\\d+)', line)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            loss = float(match.group(2))\n",
    "            if epoch not in epoch_data:\n",
    "                epoch_data[epoch] = {'train_loss': None, 'train_acc': None, 'val_loss': None, 'val_acc': None}\n",
    "            epoch_data[epoch]['train_loss'] = loss\n",
    "            continue\n",
    "        match = re.search(r'Epoch (\\d+) Training ACC = (\\d+\\.\\d+)', line)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            acc = float(match.group(2))\n",
    "            if epoch not in epoch_data:\n",
    "                epoch_data[epoch] = {'train_loss': None, 'train_acc': None, 'val_loss': None, 'val_acc': None}\n",
    "            epoch_data[epoch]['train_acc'] = acc\n",
    "            continue\n",
    "        match = re.search(r'Epoch (\\d+) Validation Loss = (\\d+\\.\\d+)', line)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            val_loss = float(match.group(2))\n",
    "            if epoch not in epoch_data:\n",
    "                epoch_data[epoch] = {'train_loss': None, 'train_acc': None, 'val_loss': None, 'val_acc': None}\n",
    "            epoch_data[epoch]['val_loss'] = val_loss\n",
    "            continue\n",
    "        match = re.search(r'Epoch (\\d+) Validation ACC = (\\d+\\.\\d+)', line)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            val_acc = float(match.group(2))\n",
    "            if epoch not in epoch_data:\n",
    "                epoch_data[epoch] = {'train_loss': None, 'train_acc': None, 'val_loss': None, 'val_acc': None}\n",
    "            epoch_data[epoch]['val_acc'] = val_acc\n",
    "            continue\n",
    "\n",
    "epochs = sorted(epoch_data.keys())\n",
    "train_losses = [epoch_data[e]['train_loss'] for e in epochs]\n",
    "train_accuracies = [epoch_data[e]['train_acc'] for e in epochs]\n",
    "val_losses = [epoch_data[e]['val_loss'] for e in epochs]\n",
    "val_accuracies = [epoch_data[e]['val_acc'] for e in epochs]\n",
    "\n",
    "best_epoch_accuracy = val_accuracies.index(max(val_accuracies))\n",
    "best_val_accuracy = val_accuracies[best_epoch_accuracy]\n",
    "print(f\"The best epoch based on validation accuracy is: {best_epoch_accuracy + 1}, with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'saved_model_our_cnn/epoch_100.h5', custom_objects={'l2_loss': l2_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_labels_train = np.load('traindata_concate_35\\label_train.npy')\n",
    "x_test_gesture = np.load('traindata_concate_35\\data_test.npy')\n",
    "\n",
    "gesture_labels_test = np.load('traindata_concate_35\\label_test.npy')\n",
    "\n",
    "x_test_gesture = x_test_gesture.reshape(-1, 32, 32, 4)\n",
    "\n",
    "gesture_labels_train = np.repeat(gesture_labels_train, 35)\n",
    "gesture_labels_test = np.repeat(gesture_labels_test, 35)\n",
    "\n",
    "print(\"Gesture labels train shape:\", np.shape(gesture_labels_train))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "gesture_labels_train_encoded = label_encoder.fit_transform(gesture_labels_train)\n",
    "gesture_labels_test_encoded = label_encoder.transform(gesture_labels_test)\n",
    "\n",
    "gesture_labels_train_one_hot = to_categorical(gesture_labels_train_encoded).reshape(-1, 1, 11)\n",
    "gesture_labels_test_one_hot = to_categorical(gesture_labels_test_encoded).reshape(-1, 1, 11)\n",
    "\n",
    "print(\"Reshaped Gesture labels train shape:\", gesture_labels_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook BN Layer\n",
    "hook=[]\n",
    "id=[10]\n",
    "for i in range(len(id)):\n",
    "  hook.append(model.layers[id[i]].output)\n",
    "ModelExtract = Model(inputs=model.input, outputs=hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def process_data_in_groups(data, model, save_dir, prefix, num_segments=15, group_size=5):\n",
    "    \"\"\"\n",
    "    Splits the data into `num_segments` parts, processes them in groups of `group_size`,\n",
    "    saves intermediate group predictions to disk, then concatenates them to form final predictions.\n",
    "    \n",
    "    Parameters:\n",
    "      data (np.array): The input data (e.g., x_train_gesture or x_test_gesture).\n",
    "      model (keras.Model): The model to use for prediction.\n",
    "      save_dir (str): Directory to save the intermediate and final prediction files.\n",
    "      prefix (str): File name prefix, e.g., 'train' or 'test'.\n",
    "      num_segments (int): Total number of segments to split the data into.\n",
    "      group_size (int): Process predictions in groups of this many segments.\n",
    "      \n",
    "    Returns:\n",
    "      np.array: The final concatenated predictions.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    data_segments = np.array_split(data, num_segments)\n",
    "    group_file_paths = []\n",
    "    \n",
    "    for group_idx in range(0, num_segments, group_size):\n",
    "        current_segment_files = []\n",
    "        for i in range(group_idx, min(group_idx + group_size, num_segments)):\n",
    "            preds = model.predict(data_segments[i])\n",
    "            seg_file_name = f'{prefix}_segment_{i}.npy'\n",
    "            seg_file_path = os.path.join(save_dir, seg_file_name)\n",
    "            np.save(seg_file_path, preds)\n",
    "            current_segment_files.append(seg_file_path)\n",
    "\n",
    "        group_preds = np.concatenate([np.load(file) for file in current_segment_files], axis=0)\n",
    "        group_file_name = f'{prefix}_group_{group_idx // group_size}.npy'\n",
    "        group_file_path = os.path.join(save_dir, group_file_name)\n",
    "        np.save(group_file_path, group_preds)\n",
    "        group_file_paths.append(group_file_path)\n",
    "        \n",
    "        for file in current_segment_files:\n",
    "            os.remove(file)\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        print(f\"[{prefix}] Processed group {group_idx // group_size + 1} (segments {group_idx} to {min(group_idx+group_size, num_segments)-1}).\")\n",
    "\n",
    "    final_preds = np.concatenate([np.load(file) for file in group_file_paths], axis=0)\n",
    "    final_file_path = os.path.join(save_dir, f'data_{prefix}.npy')\n",
    "    np.save(final_file_path, final_preds)\n",
    "    print(f\"[{prefix}] Final predictions saved to {final_file_path}\")\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "save_directory = 'Stage1_LSTM'\n",
    "\n",
    "train_predictions = process_data_in_groups(\n",
    "    data=x_train_gesture,\n",
    "    model=ModelExtract,\n",
    "    save_dir=save_directory,\n",
    "    prefix='train',\n",
    "    num_segments=15,\n",
    "    group_size=5\n",
    ")\n",
    "\n",
    "test_predictions = process_data_in_groups(\n",
    "    data=x_test_gesture,\n",
    "    model=ModelExtract,\n",
    "    save_dir=save_directory,\n",
    "    prefix='test',\n",
    "    num_segments=15,\n",
    "    group_size=5\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KKT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
