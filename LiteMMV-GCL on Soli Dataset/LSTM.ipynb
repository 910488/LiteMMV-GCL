{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv1D, TimeDistributed, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = tf.keras.layers.Input(shape=(35,128))\n",
    "x = tf.keras.layers.LSTM(units=128, activation=\"tanh\", time_major=False, return_sequences=True)(main_input)\n",
    "x = tf.keras.layers.Dense(11, activation=None)(x)\n",
    "x = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=main_input, outputs=x)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'], weighted_metrics=[])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = tf.keras.layers.Input(shape=(35,128))\n",
    "x = tf.keras.layers.LSTM(units=128, activation=\"tanh\", time_major=False, return_sequences=True)(main_input)\n",
    "x = tf.keras.layers.Dense(11, activation=None)(x)\n",
    "x = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=main_input, outputs=x)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'], weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "predictions_train = np.load('Stage1_LSTM/predictions_train.npy')\n",
    "labels_train = np.load('Stage1_LSTM/predictions_labels_train.npy')\n",
    "\n",
    "predictions_test = np.load('Stage1_LSTM/predictions_test.npy')\n",
    "labels_test = np.load('Stage1_LSTM/predictions_labels_test.npy')\n",
    "\n",
    "data_train = []\n",
    "data_train_labels = []\n",
    "\n",
    "for i in range(10000000):\n",
    "    if i + 35 > len(predictions_train):\n",
    "        break\n",
    "    data_train.append(predictions_train[i:i + 35, :])\n",
    "    data_train_labels.append(labels_train[i:i+35, :])\n",
    "\n",
    "print(np.shape(data_train))\n",
    "print(np.shape(data_train_labels))\n",
    "\n",
    "data_train = np.array(data_train)\n",
    "data_train_labels = np.array(data_train_labels)\n",
    "indices = np.arange(len(data_train))\n",
    "np.random.shuffle(indices)\n",
    "data_train = data_train[indices]\n",
    "data_train_labels = data_train_labels[indices]\n",
    "\n",
    "data_test = []\n",
    "data_test_labels = []\n",
    "\n",
    "for i in range(10000000):\n",
    "    if i + 35 > len(predictions_test):\n",
    "        break\n",
    "    data_test.append(predictions_test[i:i + 35, :])\n",
    "    data_test_labels.append(labels_test[i:i+35, :])\n",
    "\n",
    "print(np.shape(data_test))\n",
    "print(np.shape(data_test_labels))\n",
    "\n",
    "def evaluate_data(model, x_data, y_data, batch_size, num_segments=10):\n",
    "    segment_size = len(x_data) // num_segments\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    cce = CategoricalCrossentropy()\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size if i < num_segments - 1 else len(x_data)\n",
    "\n",
    "        x_segment = x_data[start_idx:end_idx]\n",
    "        y_segment = y_data[start_idx:end_idx]\n",
    "\n",
    "        preds = model.predict(x_segment, batch_size=batch_size, verbose=0)  # (batch, timesteps, num_classes)\n",
    "        y_last = y_segment[:, -1, :]            # (batch, num_classes)\n",
    "        preds_last = preds[:, -1, :]            # (batch, num_classes)\n",
    "\n",
    "        # Loss\n",
    "        loss = cce(y_last, preds_last).numpy()\n",
    "        total_loss += loss * y_last.shape[0]\n",
    "\n",
    "        # Accuracy\n",
    "        pred_label = np.argmax(preds_last, axis=1)\n",
    "        true_label = np.argmax(y_last, axis=1)\n",
    "        acc = np.sum(pred_label == true_label)\n",
    "        total_acc += acc\n",
    "        total_samples += y_last.shape[0]\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_acc / total_samples\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "# Train the model\n",
    "def AGIprogressBar(count, total,start):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    duration=time.time()-start\n",
    "    print('\\r[%s] %s%s ...%s sec' % (bar, percents, '%', duration),end=' ')\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "Batch = 2400\n",
    "epochs = 100\n",
    "segment_count = 15\n",
    "st = time.time()\n",
    "\n",
    "for ep in range(epochs):\n",
    "    print(f'EP: {ep + 1}')\n",
    "    segment_size = len(data_train) // segment_count\n",
    "    for seg in range(segment_count):\n",
    "        start_idx = seg * segment_size\n",
    "        end_idx = start_idx + segment_size\n",
    "\n",
    "        x_segment = data_train[start_idx:end_idx]\n",
    "        y_segment = data_train_labels[start_idx:end_idx]\n",
    "\n",
    "        indices = np.arange(len(x_segment))\n",
    "        np.random.shuffle(indices)\n",
    "        x_segment = data_train[indices]\n",
    "        y_segment = data_train_labels[indices]\n",
    "\n",
    "        for i in range(len(x_segment) // Batch):\n",
    "            AGIprogressBar(i, len(x_segment) // Batch, st)\n",
    "            x_batch = x_segment[i * Batch:(i + 1) * Batch]\n",
    "            y_batch = y_segment[i * Batch:(i + 1) * Batch]\n",
    "            model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "    train_loss, train_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=data_train,\n",
    "        y_data=data_train_labels,\n",
    "        batch_size=2400,\n",
    "        num_segments=700\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(' ')\n",
    "    print(f'Epoch {ep + 1} Training Loss = {train_loss}')\n",
    "    print(f'Epoch {ep + 1} Training ACC = {train_acc}')\n",
    "\n",
    "    os.makedirs('saved_model_our_LSTM', exist_ok=True)\n",
    "    model.save(f'saved_model_our_LSTM/LSTM_epoch_{ep + 1}.h5')\n",
    "    print(f'Model saved at epoch {ep + 1}')\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    model = load_model(f'saved_model_our_LSTM/LSTM_epoch_{ep + 1}.h5')\n",
    "\n",
    "    val_loss, val_acc = evaluate_data(\n",
    "        model=model,\n",
    "        x_data=np.array(data_test),\n",
    "        y_data=np.array(data_test_labels),\n",
    "        batch_size=2400,\n",
    "        num_segments=700\n",
    "    )\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {ep + 1} Validation Loss = {val_loss}')\n",
    "    print(f'Epoch {ep + 1} Validation ACC = {val_acc}')\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    model = load_model(f'saved_model_our_LSTM/LSTM_epoch_{ep + 1}.h5')\n",
    "\n",
    "best_epoch_accuracy = val_accuracies.index(max(val_accuracies))\n",
    "best_val_accuracy = val_accuracies[best_epoch_accuracy]\n",
    "print(f\"The best epoch based on validation accuracy is: {best_epoch_accuracy + 1}, with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('saved_model_our_LSTM/LSTM_epoch_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.load('Stage1_LSTM\\predictions_train.npy')\n",
    "train_data_label = np.load('Stage1_LSTM\\predictions_labels_train.npy')\n",
    "\n",
    "data_train = []\n",
    "data_train_labels = []\n",
    "\n",
    "for i in range(1000000000):\n",
    "    if i + 35 > len(train_data):\n",
    "        break\n",
    "    data_train.append(train_data[i:i + 35, :])\n",
    "    data_train_labels.append(train_data_label[i:i+35, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_CM_data(model, x_data, y_data, batch_size, num_segments=10):\n",
    "    segment_size = len(x_data) // num_segments\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size if i < num_segments - 1 else len(x_data)\n",
    "\n",
    "        x_segment = x_data[start_idx:end_idx]\n",
    "        y_segment = y_data[start_idx:end_idx]\n",
    "\n",
    "        predictions = model.predict(x_segment, batch_size=batch_size, verbose=0)\n",
    "        \n",
    "        pred = np.argmax(predictions[:, -1, :], axis=1)\n",
    "        true = np.argmax(y_segment[:, -1, :], axis=1)\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true)\n",
    "\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_trues)\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.array(data_test)\n",
    "data_test_labels = np.array(data_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['gesture_0', 'gesture_1', 'gesture_2', 'gesture_3', 'gesture_4', 'gesture_5', 'gesture_6', 'gesture_7', 'gesture_8', 'gesture_9', 'gesture_10']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(100,12))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f', ax=ax)\n",
    "\n",
    "for text in disp.text_.ravel():\n",
    "    if text.get_text():\n",
    "        text.set_text(f\"{float(text.get_text()):.2f}%\")\n",
    "\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "\n",
    "plt.title('LiteMMV-GCL for Hand Gesture Classification on Soli Dataset')\n",
    "plt.subplots_adjust(left=0.2, right=0.3, top=0.9, bottom=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook Layers\n",
    "hook=[]\n",
    "id=[0, 1, 2, 3]\n",
    "for i in range(len(id)):\n",
    "  hook.append(model.layers[id[i]].output)\n",
    "ModelExtract = Model(inputs=model.input, outputs=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelExtract.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data_test)\n",
    "for i in range(n):\n",
    "    j = np.random.randint(i, n)\n",
    "    # Swap rows i and j for data and labels\n",
    "    data_test[[i, j]], data_test[[j, i]] = data_test[[j, i]], data_test[[i, j]]\n",
    "    data_test_labels[[i, j]], data_test_labels[[j, i]] = data_test_labels[[j, i]], data_test_labels[[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ModelExtract.predict(data_test[:20000])\n",
    "labels = np.argmax(data_test_labels[:20000][:, -1, :], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from matplotlib import pyplot as plt\n",
    "PCA=[]\n",
    "\n",
    "classes = ['gesture_0', 'gesture_1', 'gesture_2', 'gesture_3', 'gesture_4', 'gesture_5', 'gesture_6', 'gesture_7', 'gesture_8', 'gesture_9', 'gesture_10']\n",
    "\n",
    "label_to_color = {\n",
    "    'gesture_0': [1, 0, 0, 1],           # Red\n",
    "    'gesture_1': [0, 0.5, 0, 1],         # Green\n",
    "    'gesture_2': [0, 0, 1, 1],           # Blue\n",
    "    'gesture_3': [1, 0.65, 0, 1],        # Orange\n",
    "    'gesture_4': [1, 1, 0, 1],           # Yellow\n",
    "    'gesture_5': [0, 0, 0, 1],           # Black\n",
    "    'gesture_6': [0.93, 0.51, 0.93, 1],  # Violet\n",
    "    'gesture_7': [0.5, 0, 0.5, 1],       # Purple\n",
    "    'gesture_8': [0, 1, 1, 1],           # Cyan\n",
    "    'gesture_9': [0.5, 0.5, 0.5, 1],     # Gray\n",
    "    'gesture_10': [0.6, 0.2, 0.2, 1],    # Brown\n",
    "    'BG_Static': [0.75, 0.75, 0, 1]      # Olive\n",
    "}\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    input=np.reshape(predictions[i],[len(predictions[i]),-1])\n",
    "    pca=decomposition.PCA(n_components=2)\n",
    "    pca.fit(input)\n",
    "    PCA.append(pca)\n",
    "    Dim2=PCA[-1].transform(input)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if model.layers[id[i]].name == 'input_1':\n",
    "        title = \"Gesture Class Distribution in Soli Dataset via PCA using LiteMMV-GCL (LSTM Input Layer)\"\n",
    "    elif model.layers[id[i]].name == 'dense':\n",
    "        title = \"Learned Feature Distribution in Soli Dataset via PCA using LiteMMV-GCL (LSTM Dense Layer)\"\n",
    "    else:\n",
    "        title = model.layers[id[i]].name+': '+f'{predictions[i].shape}'\n",
    "    plt.title(title)\n",
    "    for cl in range(11):\n",
    "        chos=Dim2[np.argwhere(labels==cl).reshape([-1])]\n",
    "        color = label_to_color[classes[cl]]\n",
    "        plt.scatter(chos[:, 0], \n",
    "                   chos[:, 1], \n",
    "                   label=classes[cl],\n",
    "                   facecolors='none',\n",
    "                   edgecolors=color,\n",
    "                   marker='o', \n",
    "                   s=10)\n",
    "    plt.savefig(title, dpi=300, bbox_inches='tight')\n",
    "    plt.legend(loc=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KKT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
